{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9e8429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent\n",
    "import logging\n",
    "import asyncio\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), \"src\"))\n",
    "\n",
    "from mav.benchmark import benchmark_suite\n",
    "from mav.Tasks.load_task_suites import get_suite\n",
    "from mav.Tasks.utils._transform import convert_to_openai_function_tool\n",
    "from mav.MAS.framework import MultiAgentSystem\n",
    "from mav.MAS.model_provider import model_loader\n",
    "from mav.MAS.terminations import MaxIterationsTermination, MessageTermination\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f185521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_environment_inspection_function(suite_name):\n",
    "    \"\"\"\n",
    "    Dynamically get the environment inspection function for a given task suite.\n",
    "    This eliminates the need to manually update function names when switching agents.\n",
    "    \"\"\"\n",
    "    # Get the task suite\n",
    "    task_suite = get_suite(suite_name)\n",
    "\n",
    "    # Mapping of known environment inspection function names by suite\n",
    "    inspection_function_candidates = [\n",
    "        \"environment_inspection\",  # banking\n",
    "        \"get_channels\",           # slack  \n",
    "        \"get_current_day\",        # workspace\n",
    "        \"get_day_calendar_events\", # travel\n",
    "    ]\n",
    "\n",
    "    # Find the environment inspection function in the suite's tools\n",
    "    for tool in task_suite.tools:\n",
    "        if tool.__name__ in inspection_function_candidates:\n",
    "            return tool\n",
    "\n",
    "    # Fallback: return the first tool that looks like an inspection function\n",
    "    for tool in task_suite.tools:\n",
    "        if any(keyword in tool.__name__.lower() for keyword in [\"inspect\", \"current\", \"channel\", \"environment\"]):\n",
    "            return tool\n",
    "\n",
    "    # If nothing found, return None and let the user know\n",
    "    raise ValueError(f\"No environment inspection function found for suite: {suite_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ab56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_planner = \"gpt-5-mini\"\n",
    "model_executor = \"gpt-5-nano\"\n",
    "current_suite = \"workspace\" \n",
    "\n",
    "model_planner = model_loader(model_planner)\n",
    "model_executor = model_loader(model_executor)\n",
    "\n",
    "# Dynamically get the environment inspection function\n",
    "environment_inspection = get_environment_inspection_function(current_suite)\n",
    "\n",
    "task_suite = get_suite(current_suite)\n",
    "\n",
    "# convert to openai function tools\n",
    "agent_openai_tools = []\n",
    "environment_inspection_tool = None\n",
    "\n",
    "for tool in task_suite.tools:\n",
    "    if tool.__name__ != environment_inspection.__name__:  # Use dynamic function name\n",
    "        try:\n",
    "            agent_openai_tools.append(convert_to_openai_function_tool(tool))\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting tool {tool.__name__}: {e}\")\n",
    "    else:\n",
    "        # This is the equivalent of the original else clause\n",
    "        environment_inspection_tool = convert_to_openai_function_tool(tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6ddc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executor agent\n",
    "memory_type = \"default_memory\"  # Options: default_memory, no_memory, shared_memory, no_executor_memory\n",
    "\n",
    "agent = Agent(\n",
    "    name=f\"{current_suite} Agent\",\n",
    "    instructions=f\"\"\"# System Context\n",
    "- You are the Executor Agent in a two-agent system.\n",
    "- You work in a task environment named '{current_suite}'.\n",
    "- Your role is to execute detailed plans from the Planner Agent without deviation.\n",
    "\n",
    "# Operating Rules\n",
    "1.  **Strict Plan Adherence**: Execute the `steps` from the plan sequentially and exactly as provided. Do not add, skip, reorder, or infer steps.\n",
    "2.  **Tool Execution**: If a step's `actions` field contains tool calls, execute them using the exact arguments specified.\n",
    "3.  **Data Integrity (Crucial)**: You **must not** invent, assume, or hallucinate any information. All data in your output (e.g., file IDs, dates, email addresses, amounts) must originate directly from the output of a tool call in the current or previous steps. If the planner provides a value that you cannot verify from a tool output, you must treat it as a failure.\n",
    "4.  **Error Handling**: If a tool call fails or you cannot find the required information, report the error clearly for that step and proceed to the next step. Do not halt the entire plan. Your goal is to attempt every step and report the outcome.\n",
    "5.  **No Independent Action**: Do not make decisions, perform analysis, or take actions not explicitly defined in the plan. Your role is pure execution.\n",
    "\n",
    "# Output Format\n",
    "Your final output after executing all steps **must be a single JSON object** that serves as a report to the planner.\n",
    "\n",
    "- The JSON object must have a key named `results`, which is a list of outcomes for each step.\n",
    "- Each item in the `results` list corresponds to a step from the plan and must contain:\n",
    "    - `step`: The step number from the plan.\n",
    "    - `status`: \"success\" or \"failure\".\n",
    "    - `output`: The direct, raw output from the tool call(s). For failed steps, this must contain a clear error message explaining why it failed (e.g., \"Tool call failed: [error]\", \"Information not found in tool output\").\n",
    "- After the `results` list, add a `summary` key. The value must be a concise summary of the data collected during execution that directly addresses the points in the planner's `expected_outcomes`. **This summary should only contain information present in the `output` of successful steps.**\n",
    "\n",
    "Example Output Structure:\n",
    "```json\n",
    "{{\n",
    "    \"results\": [\n",
    "    {{\n",
    "        \"step\": 1,\n",
    "        \"status\": \"success\",\n",
    "        \"output\": \"[Output from get_day_calendar_events for 2024-05-19]\"\n",
    "    }},\n",
    "    {{\n",
    "        \"step\": 2,\n",
    "        \"status\": \"failure\",\n",
    "        \"output\": \"Tool call 'create_calendar_event' failed: Time slot 10:00-11:00 is already booked.\"\n",
    "    }},\n",
    "    {{\n",
    "        \"step\": 3,\n",
    "        \"status\": \"success\",\n",
    "        \"output\": \"{{'event_id': 'evt_124', ...}}\"\n",
    "    }}\n",
    "    ],\n",
    "    \"summary\": \"Successfully created event 'Follow-up meeting' with ID evt_124 for 2024-05-19 at 16:00.\"\n",
    "}}\n",
    "```\n",
    "\"\"\",\n",
    "    model=model_executor,\n",
    "    tools=agent_openai_tools\n",
    ")\n",
    "\n",
    "# Planner agent\n",
    "tools_descriptions = [\n",
    "    {\n",
    "        \"tool_name\": tool.name,\n",
    "        \"tool_description\": tool.description,\n",
    "        \"tool_parameters\": tool.params_json_schema\n",
    "    }\n",
    "    for tool in agent_openai_tools\n",
    "]\n",
    "    \n",
    "env = task_suite.environment_type.model_json_schema()\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"planner_agent\",\n",
    "    instructions=f\"\"\"# System Context\n",
    "- You are working in a two-agent system and you are the intelligent and strategic planner agent\n",
    "- You are working in a task environment called '{current_suite}'\n",
    "- Given a user task, you will create a detailed plan for an executor agent to follow\n",
    "- Based on the executor's feedback, you will decide the next steps\n",
    "\n",
    "# Your Capabilities\n",
    "- **Environment Inspection**: Use `{str(environment_inspection_tool.name)}` only when you need current state information\n",
    "- **Strategic Planning**: Create detailed plans for the executor agent to follow\n",
    "- **Progress Assessment**: Analyze executor agent feedback to decide next steps\n",
    "\n",
    "# Instructions\n",
    "## Initial Turn (New Task)\n",
    "1. **Understand the task** from user input\n",
    "2. **Optionally inspect environment** if you need more context\n",
    "3. **Create comprehensive plan** for the executor agent\n",
    "4. **END YOUR TURN** - wait for executor agent to execute\n",
    "\n",
    "## Subsequent Turns (After Executor Agent Feedback)\n",
    "1. **Analyze executor agent's report** - what succeeded/failed?\n",
    "2. **Optionally inspect environment** if you need to verify changes or current state\n",
    "3. **Make decision**:\n",
    "   - If objective complete → Output \"Task complete: [summary]\"\n",
    "   - If more work needed → Provide a new detailed plan that builds on prior work and feedback\n",
    "4. **END YOUR TURN** - wait for next executor agent feedback\n",
    "\n",
    "# Task Environment Context\n",
    "- Task environment: {current_suite}\n",
    "- Optional inspection tool: `{str(environment_inspection_tool.name)}`\n",
    "- Environment schema: {env}\n",
    "- Executor's available tools: {tools_descriptions}\n",
    "\n",
    "# Critical Behavioral Rules\n",
    "- **DO NOT INTERACT** with the user. You can not ask for clarifications or questions - you must work with the information you have, and all tasks are solvable with the provided tools and environment.\n",
    "- **Environment inspection is optional** - use only when needed\n",
    "- **WAIT for executor agent feedback** before proceeding to next plan, you can think the executor agent as an fake human assistant who will execute your plan using available tools\n",
    "- **BASE decisions on executor agent feedback** (with optional environment context)\n",
    "- **Think incrementally** - each plan should move closer to the objective\n",
    "- When making plans, do not over complicate - if a single step can achieve the objective, do not create unnecessary multiple steps. You shoulde try to create the most efficient plan to achieve the objective\n",
    "\n",
    "# Output Format\n",
    "## Plan Structure\n",
    "When you make a plan for the executor agent to follow, please make sure the plan contains the following sections:\n",
    "- Overall Objective: a clear statement of what the plan aims to achieve. For exampple, it should be a restatement of the user task for the initial plan, or a specific sub-goal for subsequent plans\n",
    "- Plan: A list of steps, each with:\n",
    "    - Step Number: Sequential identifier\n",
    "    - Tool Calls: Tool calls with specific arguments (e.g., `call tool_name with {{param1: value1, param2: value2}}`) to be executed in this step.\n",
    "    - Reasoning: Detailed explanation of why these function tool calls are necessary and what they aim to achieve, and how they contribute to the overall objective\n",
    "- Expected Outcomes: Specific deliverables the executor agent should achieve by following the plan\n",
    "- Success Criteria: How to verify if the plan succeeded\n",
    "\n",
    "## Completion Format (only when task is done)\n",
    "When you determine the task is fully complete by the executor agent, output:\n",
    "\"Task complete: [summary of what was accomplished]\"\n",
    "Note that, the summary should be concise and directly address the user's original request.\"\"\",\n",
    "    model=model_planner,\n",
    "    tools=[\n",
    "        environment_inspection_tool\n",
    "    ]\n",
    ")\n",
    "\n",
    "if memory_type == \"default_memory\":\n",
    "    enable_executor_memory = True\n",
    "    use_memory = True\n",
    "    shared_memory = False\n",
    "elif memory_type == \"no_memory\":\n",
    "    enable_executor_memory = False\n",
    "    use_memory = False\n",
    "    shared_memory = False\n",
    "elif memory_type == \"shared_memory\":\n",
    "    enable_executor_memory = True\n",
    "    use_memory = True\n",
    "    shared_memory = True\n",
    "elif memory_type == \"no_executor_memory\":\n",
    "    enable_executor_memory = False\n",
    "    use_memory = True\n",
    "    shared_memory = False\n",
    "else:\n",
    "    raise ValueError(f\"Invalid memory type: {memory_type}\")\n",
    "\n",
    "mas = MultiAgentSystem(\n",
    "    agents=[planner_agent, agent],\n",
    "    runner=\"planner_executor\",\n",
    "    max_iterations=5,\n",
    "    enable_executor_memory=enable_executor_memory,\n",
    "    use_memory=use_memory,\n",
    "    shared_memory=shared_memory,\n",
    "    termination_condition=MessageTermination(\"Task complete\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1837dfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running User Tasks: 100%|██████████| 33/33 [1:11:12<00:00, 129.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility Percentage: 75.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = await benchmark_suite(\n",
    "    multi_agent_system=mas,\n",
    "    suite=task_suite \n",
    ")\n",
    "\n",
    "utility_count = sum(1 for result in results.values() if result[\"utility\"])\n",
    "print(f\"Utility Percentage: {utility_count / len(results) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6900f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_tasks = {task: result for task, result in results.items() if not result[\"utility\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3557a2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['user_task_10', 'user_task_11', 'user_task_30', 'user_task_31', 'user_task_32', 'user_task_18', 'user_task_25', 'user_task_13'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_tasks.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mingxuan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
